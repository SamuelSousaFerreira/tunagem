{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install lightgbm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install optuna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://mariofilho.com/lightgbm-tuning-hiperparametros-optuna/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao ajustar seus hiperparâmetros primeiro, você vai espremer cada gota de desempenho do seu modelo com os dados que já tem.  \n",
    "Depois que você tiver os hiperparâmetros ideais, você passa para a engenharia de features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A primeira coisa a considerar é o número de árvores que você vai treinar, também conhecido como *num_iterations*.\n",
    "\n",
    "Quanto mais árvores você tiver, mais estáveis serão suas previsões.\n",
    "\n",
    "Então, quantas árvores você deve escolher? Depende do caso de uso do seu modelo.\n",
    "\n",
    "Se o seu modelo precisa entregar resultados com baixa latência (por exemplo: negociação de alta frequência, previsão de cliques em anúncios), você pode limitar o número de árvores para cerca de 200.\n",
    "\n",
    "No entanto, se o seu modelo é executado uma vez por semana (por exemplo: previsão de vendas) e tem mais tempo para fazer as previsões, você pode considerar usar até 5.000 árvores.\n",
    "Como regra geral, comece fixando o número de árvores e depois foque em tunar a learning_rate.\n",
    "\n",
    "Isso controla quanto cada árvore contribui para a previsão final.\n",
    "\n",
    "Quanto mais árvores você tiver, menor deve ser a taxa de aprendizado.\n",
    "\n",
    "O intervalo recomendado para a taxa de aprendizado é entre 0,001 e 0,1.\n",
    "Em seguida, temos o num_leaves.\n",
    "\n",
    "Isso determina a complexidade de cada árvore em seu modelo.\n",
    "\n",
    "Você pode pensar nisso como o equivalente ao parâmetro max_depth em outros modelos baseados em árvores.\n",
    "\n",
    "Refere-se ao número máximo de nós terminais, ou folhas, que cada árvore pode ter.\n",
    "\n",
    "Em uma árvore de decisão, uma folha representa uma decisão ou um resultado.\n",
    "Ao aumentar o num_leaves, você permite que a árvore cresça mais complexa, criando um número maior de caminhos de decisão distintos.\n",
    "\n",
    "Isso pode levar a um modelo mais flexível que pode capturar padrões complexos nos dados.\n",
    "\n",
    "No entanto, aumentar o número de folhas também pode fazer com que o modelo sofra overfitting dos dados de treinamento, pois terá uma quantidade menor de dados por folha.\n",
    "\n",
    "Eu gosto de tuná-lo em potências de 2, começando de 2 e indo até 1024.\n",
    "\n",
    "O hiperparâmetro subsample desempenha um papel no controle da quantidade de dados usados para construir cada árvore em seu modelo.\n",
    "\n",
    "É uma fração que varia de 0 a 1, representando a proporção do conjunto de dados a ser selecionada aleatoriamente para treinar cada árvore.\n",
    "\n",
    "Ao usar apenas um subconjunto dos dados para cada árvore, o modelo pode se beneficiar da diversidade e reduzir a correlação entre as árvores, o que pode ajudar a combater o overfitting.\n",
    "\n",
    "Lembre-se de definir bagging_freq como um valor positivo ou o LightGBM ignorará o subsample.\n",
    "\n",
    "bagging_freq é a frequência com que os dados são amostrados.\n",
    "\n",
    "Defini-lo como 1 significa reamostrar os dados antes da construção de cada árvore, que é o comportamento padrão de outros modelos baseados em árvores.\n",
    "\n",
    "O intervalo que eu uso para subsample é entre 0,05 e 1.\n",
    "\n",
    "O hiperparâmetro colsample_bytree é outro aspecto importante a considerar ao tunar seu modelo LightGBM.\n",
    "\n",
    "Ele determina a proporção de features a serem usadas para cada árvore.\n",
    "\n",
    "Esse valor varia de 0 a 1, onde um valor de 1 significa que todas as features serão consideradas para cada árvore, e um valor menor indica que apenas um subconjunto de features será escolhido aleatoriamente antes de construir cada árvore.\n",
    "\n",
    "Este método também é conhecido como Random Subspace.\n",
    "\n",
    "Os hiperparâmetros subsample e colsample_bytree no LightGBM o tornam semelhante às Random Forests, já que este último amostra linhas (com reposição) e colunas para cada árvore.\n",
    "\n",
    "Mesmo que esses hiperparâmetros façam o LightGBM e as Random Forests parecerem semelhantes, eles são algoritmos diferentes.\n",
    "\n",
    "LightGBM é um método de gradient boosting, enquanto Random Forests é um método de bagging, o que significa que eles aprendem com os dados de maneiras diferentes.\n",
    "\n",
    "Finalmente, o hiperparâmetro min_data_in_leaf define o número mínimo de pontos de dados que devem estar presentes em nós terminais de cada árvore.\n",
    "\n",
    "Este parâmetro ajuda a controlar a complexidade do modelo e previne o overfitting.\n",
    "\n",
    "Pense nisso, se você tem um nó terminal com apenas uma amostra, seu rótulo será o valor desse único ponto de dados.\n",
    "\n",
    "Se você tem um nó terminal com 30 amostras, seu rótulo será a média desses 30 pontos de dados.\n",
    "\n",
    "É estatisticamente melhor tomar decisões com base em mais pontos de dados.\n",
    "\n",
    "Isso não significa que você deva definir min_data_in_leaf com um valor alto, pois isso tornará seu modelo menos flexível e mais propenso ao underfitting.\n",
    "\n",
    "Eu gosto de mantê-lo na faixa de 1 a 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\n",
    "data = pd.read_csv(url, delimiter=\";\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(\"quality\", axis=1)\n",
    "y = data[\"quality\"]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Os métodos trial.suggest_* são usados para especificar o espaço de busca para cada hiperparâmetro.\n",
    "# Por exemplo, a learning_rate é pesquisada dentro de uma escala logarítmica de 1e-3 a 0,1, e num_leaves é pesquisado dentro de um intervalo inteiro de 2 a 1024.\n",
    "#A escala logarítmica é usada para a taxa de aprendizado porque tentará mais valores próximos a 0,001, já que taxas de aprendizado pequenas com um grande número de árvores tendem a ser mais estáveis.\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"objective\": \"regression\",\n",
    "        \"metric\": \"rmse\",\n",
    "        \"n_estimators\": 1000,\n",
    "        \"verbosity\": -1,\n",
    "        \"bagging_freq\": 1,\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.1, log=True),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 2**10),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.05, 1.0),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 1, 100),\n",
    "    }\n",
    "\n",
    "    model = lgb.LGBMRegressor(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_val)\n",
    "    rmse = mean_squared_error(y_val, predictions, squared=False)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 20:18:31,483] A new study created in memory with name: no-name-a127ac6b-5d1d-467f-8261-b440b81ae676\n",
      "C:\\Users\\samue\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-08-07 20:18:32,127] Trial 0 finished with value: 0.630967302384811 and parameters: {'learning_rate': 0.0020834529080057495, 'num_leaves': 205, 'subsample': 0.7345167174218623, 'colsample_bytree': 0.23518091333262314, 'min_data_in_leaf': 34}. Best is trial 0 with value: 0.630967302384811.\n",
      "C:\\Users\\samue\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-08-07 20:18:39,940] Trial 1 finished with value: 0.566367004701517 and parameters: {'learning_rate': 0.007862712732033553, 'num_leaves': 970, 'subsample': 0.8743221792299022, 'colsample_bytree': 0.2406469276458616, 'min_data_in_leaf': 2}. Best is trial 1 with value: 0.566367004701517.\n",
      "C:\\Users\\samue\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-08-07 20:18:40,307] Trial 2 finished with value: 0.6131965029891868 and parameters: {'learning_rate': 0.002848352908924564, 'num_leaves': 417, 'subsample': 0.5538138421953673, 'colsample_bytree': 0.38055335880055324, 'min_data_in_leaf': 46}. Best is trial 1 with value: 0.566367004701517.\n",
      "C:\\Users\\samue\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-08-07 20:18:40,839] Trial 3 finished with value: 0.6479868768030562 and parameters: {'learning_rate': 0.024662312093258223, 'num_leaves': 709, 'subsample': 0.78619963636957, 'colsample_bytree': 0.06861397486151648, 'min_data_in_leaf': 26}. Best is trial 1 with value: 0.566367004701517.\n",
      "C:\\Users\\samue\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-08-07 20:18:41,260] Trial 4 finished with value: 0.591580659741419 and parameters: {'learning_rate': 0.003917119077829347, 'num_leaves': 689, 'subsample': 0.6247741504749132, 'colsample_bytree': 0.8418473696689915, 'min_data_in_leaf': 52}. Best is trial 1 with value: 0.566367004701517.\n",
      "C:\\Users\\samue\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-08-07 20:18:42,243] Trial 5 finished with value: 0.5506270671830402 and parameters: {'learning_rate': 0.060209384671914286, 'num_leaves': 140, 'subsample': 0.6905622690910436, 'colsample_bytree': 0.3382663296924122, 'min_data_in_leaf': 14}. Best is trial 5 with value: 0.5506270671830402.\n",
      "C:\\Users\\samue\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-08-07 20:18:42,373] Trial 6 finished with value: 0.6481194709258925 and parameters: {'learning_rate': 0.0024286366312475686, 'num_leaves': 4, 'subsample': 0.34623897912945356, 'colsample_bytree': 0.3106361835336761, 'min_data_in_leaf': 19}. Best is trial 5 with value: 0.5506270671830402.\n",
      "C:\\Users\\samue\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-08-07 20:18:42,523] Trial 7 finished with value: 0.6456356186852684 and parameters: {'learning_rate': 0.00363364890212336, 'num_leaves': 96, 'subsample': 0.27515702700225547, 'colsample_bytree': 0.1850031097640798, 'min_data_in_leaf': 64}. Best is trial 5 with value: 0.5506270671830402.\n",
      "C:\\Users\\samue\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-08-07 20:18:42,740] Trial 8 finished with value: 0.6025988267790406 and parameters: {'learning_rate': 0.047414471234235825, 'num_leaves': 393, 'subsample': 0.4502849690249575, 'colsample_bytree': 0.2851669906164665, 'min_data_in_leaf': 97}. Best is trial 5 with value: 0.5506270671830402.\n",
      "C:\\Users\\samue\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-08-07 20:18:43,406] Trial 9 finished with value: 0.5544579604131916 and parameters: {'learning_rate': 0.04483685058226846, 'num_leaves': 840, 'subsample': 0.8004216631848642, 'colsample_bytree': 0.42605125410113603, 'min_data_in_leaf': 32}. Best is trial 5 with value: 0.5506270671830402.\n",
      "C:\\Users\\samue\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-08-07 20:18:44,106] Trial 10 finished with value: 0.6192835972846469 and parameters: {'learning_rate': 0.08833307330116774, 'num_leaves': 287, 'subsample': 0.16397423797554744, 'colsample_bytree': 0.657329310870902, 'min_data_in_leaf': 5}. Best is trial 5 with value: 0.5506270671830402.\n",
      "C:\\Users\\samue\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-08-07 20:18:45,219] Trial 11 finished with value: 0.5501160647049935 and parameters: {'learning_rate': 0.02247777283944229, 'num_leaves': 881, 'subsample': 0.9474901684695101, 'colsample_bytree': 0.5485649395814268, 'min_data_in_leaf': 18}. Best is trial 11 with value: 0.5501160647049935.\n",
      "C:\\Users\\samue\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-08-07 20:18:46,440] Trial 12 finished with value: 0.5379391333556729 and parameters: {'learning_rate': 0.01511560081507466, 'num_leaves': 588, 'subsample': 0.9722340279486935, 'colsample_bytree': 0.5973687233804614, 'min_data_in_leaf': 14}. Best is trial 12 with value: 0.5379391333556729.\n",
      "C:\\Users\\samue\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-08-07 20:18:46,839] Trial 13 finished with value: 0.5736782960688749 and parameters: {'learning_rate': 0.01672783284476558, 'num_leaves': 622, 'subsample': 0.9866364717243261, 'colsample_bytree': 0.6019712630963587, 'min_data_in_leaf': 77}. Best is trial 12 with value: 0.5379391333556729.\n",
      "C:\\Users\\samue\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-08-07 20:18:47,476] Trial 14 finished with value: 0.5600768220229111 and parameters: {'learning_rate': 0.008736900457064614, 'num_leaves': 972, 'subsample': 0.9841787428279278, 'colsample_bytree': 0.7613127157438824, 'min_data_in_leaf': 42}. Best is trial 12 with value: 0.5379391333556729.\n",
      "C:\\Users\\samue\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-08-07 20:18:48,757] Trial 15 finished with value: 0.5418057797451019 and parameters: {'learning_rate': 0.01818704224872962, 'num_leaves': 555, 'subsample': 0.8923199720238492, 'colsample_bytree': 0.5155724852205064, 'min_data_in_leaf': 13}. Best is trial 12 with value: 0.5379391333556729.\n",
      "C:\\Users\\samue\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-08-07 20:18:49,046] Trial 16 finished with value: 0.5937337250637647 and parameters: {'learning_rate': 0.013768672091833644, 'num_leaves': 544, 'subsample': 0.061397626501131175, 'colsample_bytree': 0.9532449960745348, 'min_data_in_leaf': 8}. Best is trial 12 with value: 0.5379391333556729.\n",
      "C:\\Users\\samue\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-08-07 20:18:49,443] Trial 17 finished with value: 0.6549353912827902 and parameters: {'learning_rate': 0.0012760151648366002, 'num_leaves': 432, 'subsample': 0.8650812513671873, 'colsample_bytree': 0.472816323816337, 'min_data_in_leaf': 63}. Best is trial 12 with value: 0.5379391333556729.\n",
      "C:\\Users\\samue\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-08-07 20:18:50,193] Trial 18 finished with value: 0.5528198651708447 and parameters: {'learning_rate': 0.006176131638947022, 'num_leaves': 570, 'subsample': 0.8651148986207248, 'colsample_bytree': 0.718032242434691, 'min_data_in_leaf': 26}. Best is trial 12 with value: 0.5379391333556729.\n",
      "C:\\Users\\samue\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-08-07 20:18:50,706] Trial 19 finished with value: 0.5515698376418796 and parameters: {'learning_rate': 0.029335536206455046, 'num_leaves': 737, 'subsample': 0.6377300478059218, 'colsample_bytree': 0.5528631316025999, 'min_data_in_leaf': 38}. Best is trial 12 with value: 0.5379391333556729.\n",
      "C:\\Users\\samue\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-08-07 20:18:51,589] Trial 20 finished with value: 0.5395141380112981 and parameters: {'learning_rate': 0.012862196541911496, 'num_leaves': 315, 'subsample': 0.4810009418754008, 'colsample_bytree': 0.8177450763306593, 'min_data_in_leaf': 12}. Best is trial 12 with value: 0.5379391333556729.\n",
      "C:\\Users\\samue\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-08-07 20:18:52,223] Trial 21 finished with value: 0.5434756314873783 and parameters: {'learning_rate': 0.013650859163601115, 'num_leaves': 278, 'subsample': 0.461081682240215, 'colsample_bytree': 0.9889204312356836, 'min_data_in_leaf': 17}. Best is trial 12 with value: 0.5379391333556729.\n",
      "C:\\Users\\samue\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-08-07 20:18:59,040] Trial 22 finished with value: 0.5390998403823424 and parameters: {'learning_rate': 0.005693074229339445, 'num_leaves': 486, 'subsample': 0.3477171464012767, 'colsample_bytree': 0.8252397275483221, 'min_data_in_leaf': 1}. Best is trial 12 with value: 0.5379391333556729.\n",
      "C:\\Users\\samue\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-08-07 20:18:59,472] Trial 23 finished with value: 0.5761618352328219 and parameters: {'learning_rate': 0.007029653953954512, 'num_leaves': 341, 'subsample': 0.3476802677949415, 'colsample_bytree': 0.8611323271944221, 'min_data_in_leaf': 26}. Best is trial 12 with value: 0.5379391333556729.\n",
      "C:\\Users\\samue\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-08-07 20:19:05,089] Trial 24 finished with value: 0.5429911021938739 and parameters: {'learning_rate': 0.005330611440347666, 'num_leaves': 471, 'subsample': 0.5014872650833259, 'colsample_bytree': 0.8498949746880491, 'min_data_in_leaf': 2}. Best is trial 12 with value: 0.5379391333556729.\n",
      "C:\\Users\\samue\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-08-07 20:19:06,622] Trial 25 finished with value: 0.5301749359908456 and parameters: {'learning_rate': 0.011427415522997916, 'num_leaves': 628, 'subsample': 0.36345876839978203, 'colsample_bytree': 0.7239289271887817, 'min_data_in_leaf': 8}. Best is trial 25 with value: 0.5301749359908456.\n",
      "C:\\Users\\samue\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-08-07 20:19:09,557] Trial 26 finished with value: 0.5232999342981532 and parameters: {'learning_rate': 0.010480177596475996, 'num_leaves': 638, 'subsample': 0.23125773596105187, 'colsample_bytree': 0.6529908719832254, 'min_data_in_leaf': 2}. Best is trial 26 with value: 0.5232999342981532.\n",
      "C:\\Users\\samue\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-08-07 20:19:10,208] Trial 27 finished with value: 0.5633216982772373 and parameters: {'learning_rate': 0.010504701961478291, 'num_leaves': 811, 'subsample': 0.1407192153873385, 'colsample_bytree': 0.6626455123937145, 'min_data_in_leaf': 8}. Best is trial 26 with value: 0.5232999342981532.\n",
      "C:\\Users\\samue\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-08-07 20:19:10,688] Trial 28 finished with value: 0.5739019346665709 and parameters: {'learning_rate': 0.03397774897474573, 'num_leaves': 632, 'subsample': 0.23824240682823844, 'colsample_bytree': 0.6437795401947505, 'min_data_in_leaf': 22}. Best is trial 26 with value: 0.5232999342981532.\n",
      "C:\\Users\\samue\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-08-07 20:19:11,091] Trial 29 finished with value: 0.589261974083526 and parameters: {'learning_rate': 0.01037294101933867, 'num_leaves': 778, 'subsample': 0.25093945674613244, 'colsample_bytree': 0.7075774608569309, 'min_data_in_leaf': 31}. Best is trial 26 with value: 0.5232999342981532.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores hiperparâmetros:  {'learning_rate': 0.010480177596475996, 'num_leaves': 638, 'subsample': 0.23125773596105187, 'colsample_bytree': 0.6529908719832254, 'min_data_in_leaf': 2}\n",
      "Melhor RMSE:  0.5232999342981532\n"
     ]
    }
   ],
   "source": [
    "print('Melhores hiperparâmetros: ', study.best_params)\n",
    "print('Melhor RMSE: ', study.best_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
